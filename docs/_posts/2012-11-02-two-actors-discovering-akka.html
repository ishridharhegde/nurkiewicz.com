---
layout: post
title: Two actors - discovering Akka
date: '2012-11-02T20:29:00.001+01:00'
author: Tomasz Nurkiewicz
tags:
- akka
- scala
modified_time: '2012-11-05T19:35:30.355+01:00'
thumbnail: http://4.bp.blogspot.com/-1POEEU-3eGE/UJQeS4XLX_I/AAAAAAAAApU/SugXgaUObvM/s72-c/response-times1.png
blogger_id: tag:blogger.com,1999:blog-6753769565491687768.post-6026192191987177973
blogger_orig_url: https://www.nurkiewicz.com/2012/11/two-actors-discovering-akka.html
---

Hope you are having fun so far, but our application has serious performance defect. After measuring response times of the <a href="http://nurkiewicz.blogspot.no/2012/10/request-and-response-discovering-akka.html"><code>RandomOrgRandom</code> class we developed in the previous part</a> we will notice something really disturbing (the chart represents response times of subsequent invocations in milliseconds):<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-1POEEU-3eGE/UJQeS4XLX_I/AAAAAAAAApU/SugXgaUObvM/s1600/response-times1.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="419" src="http://4.bp.blogspot.com/-1POEEU-3eGE/UJQeS4XLX_I/AAAAAAAAApU/SugXgaUObvM/s640/response-times1.png" width="640" /></a></div><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-GWkDmLJJOaA/UJQeTpMvCaI/AAAAAAAAApc/8n2H6GpR4ng/s1600/response-times2.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><br /></a></div>In turns out that regularly response time (time to return one random number) is greater by several orders of magnitude (logarithmic scale!) Remembering how the actor was implemented the reason is quite obvious: our actor fetches eagerly 50 random numbers and fills the buffer, returning one number after another. If the buffer is empty, actor performs blocking I/O call to <code>random.org</code> web service which takes around half of a second. This is clearly visible on the chart - every 50th invocation is much, much slower. In some circumstances such behaviour would be acceptable (just like unpredictable garbage collection can increase latency of a response once in a while). But still let's try to improve our implementation.<br /><a name='more'></a><br /><br />Do you have any idea how we can make response times more predictable and <i>flat</i>? I suggest monitoring the buffer size and when it becomes dangerously close to being empty, we initiate fetching random numbers in background. We hope that thanks to this architectural change will never be completely empty as the background response will arrive before we hit the bottom. However, we are not forced to eagerly fetch too many random numbers. Do you remember the original naive implementation using Java synchronization? It had the same problem as our current system with just one actor. But now we will finally see the true power of actor-based Akka system. To implement the improvement suggested above we would need background thread to fetch numbers and some method of synchronization on the buffer (as it would be accessed concurrently. <br /><br />In Akka each actor is logically single-threaded, thus we are not bothered by synchronization. First we will <a href="http://en.wikipedia.org/wiki/Single_responsibility_principle">divide responsibilities</a>: one actor (<code>RandomOrgBuffer</code>) will hold the buffer of random numbers and return them when requested. Second actor (<code>RandomOrgClient</code>) will barely be responsible for fetching new batches of random numbers. When <code>RandomOrgBuffer</code> discovers low buffer level, it asks <code>RandomOrgClient</code> (by sending a message) to start fetching new random numbers. Finally when <code>RandomOrgClient</code> receives a response from the <code>random.org</code> server, it sends new batch of random numbers to <code>RandomOrgBuffer</code> (of course using a reply message again). <code>RandomOrgBuffer</code> fills the buffer with new numbers.<br /><br />Let's start from the second actor, responsible for the communication with <code>random.org</code> web service in the background. This actor initiates HTTP request when it receives <code>FetchFromRandomOrg</code> message - message holding the desired batch size to fetch. When the response arrives, we parse it and send the whole batch back to the sender (<code>RandomOrgBuffer</code> in this case). This code is quite similar to what we have already seen in <code>fetchRandomNumbers()</code>:<br /><br /><pre class="brush: scala">case class FetchFromRandomOrg(batchSize: Int)<br /><br />case class RandomOrgServerResponse(randomNumbers: List[Int])<br /><br />class RandomOrgClient extends Actor {<br />  protected def receive = LoggingReceive {<br />    case FetchFromRandomOrg(batchSize) =&gt;<br />      val url = new URL("https://www.random.org/integers/?num=" + batchSize + "&amp;min=0&amp;max=65535&amp;col=1&amp;base=10&amp;format=plain&amp;rnd=new")<br />      val connection = url.openConnection()<br />      val stream = Source.fromInputStream(connection.getInputStream)<br />      sender ! RandomOrgServerResponse(stream.getLines().map(_.toInt).toList)<br />      stream.close()<br />    }<br />  }<br /></pre>Now it's time for the actual actor handling requests from potentially multiple clients asking for single random numbers. Unfortunately the logic becomes quite complicated (but at least we don't have to worry about synchronization and thread-safety). First of all <code>RandomOrgBuffer</code> must now handle two different messages: <code>RandomRequest</code> as before coming from client code and new <code>RandomOrgServerResponse</code> (see code above) containing batch of new random numbers sent from <code>RandomOrgClient</code>. Secondly <code>RandomOrgBuffer</code> must remember that it initiated the process of fetching new random codes by sending <code>FetchFromRandomOrg</code>. Otherwise we risk starting multiple concurrent connections to <code>random.org</code> or piling them up unnecessarily.<br /><br /><pre class="brush: scala">class RandomOrgBuffer extends Actor with ActorLogging {<br /><br />  val BatchSize = 50<br /><br />  val buffer = new Queue[Int]<br />  var waitingForResponse = false<br /><br />  val randomOrgClient = context.actorOf(Props[RandomOrgClient], name="client")<br />  preFetchIfAlmostEmpty()<br /><br />  def receive = {<br />    case RandomRequest =&gt;<br />      preFetchIfAlmostEmpty()<br />      sender ! buffer.dequeue()<br />    case RandomOrgServerResponse(randomNumbers) =&gt;<br />      buffer ++= randomNumbers<br />      waitingForResponse = false<br />  }<br /><br />  private def preFetchIfAlmostEmpty() {<br />    if(buffer.size &lt;= BatchSize / 4 &amp;&amp; !waitingForResponse) {<br />      randomOrgClient ! FetchFromRandomOrg(BatchSize)<br />      waitingForResponse = true<br />    }<br />  }<br /><br />}<br /></pre>The key part is <code>preFetchIfAlmostEmpty()</code> method that initiates the process of fetching random numbers (in background, by a different actor). If the buffer level is too low (I assume 1/4 of the batch size) and we are not already waiting for a response from <code>random.org</code>, we send appropriate message to <code>RandomOrgClient</code>. We also call this method immediately on startup (when the buffer is completely empty) in order to have warmed up buffer when first request arrives. Notice how one actor can <b>create</b> an instance of another actor by calling <code>context.actorOf</code> (actually it's an <code>ActorRef</code>). <br /><br />This code contains tremendous bug, can you spot it? Imagine what will happen if suddenly <code>RandomOrgBuffer</code> receives hundreds of <code>RandomRequest</code> messages at the same time? More than the buffer size, even immediately after filling it up? Or if the request comes straight after the actor instantiation, when the buffer is still empty? Unfortunately me must handle the situation when <code>RandomRequest</code> arrives and our buffer is completely empty while the <code>random.org</code> response didn't came back yet. However we cannot simply block, waiting until the response with new random numbers batch arrives. We cannot do this from one simple reason: if we are sleeping or waiting in other way while handling <code>RandomRequest</code>, we cannot handle any other message, including <code>RandomOrgServerResponse</code> - remember that one actor can handle only one message at a time! Not only we would introduce dead-lock in our application, but also break one of the most important rules in Akka: never block or sleep inside an actor - more on that in next articles.<br /><br />Correct way of handling this situation is to have a queue of awaiting actors - which sent us <code>RandomRequest</code> but we were incapable of sending a reply immediately due to an empty buffer. As soon as we get <code>RandomOrgServerResponse</code> back, our priority is to handle these awaiting actors and then focus on subsequent requests in real time. There is an interesting edge case - if the number of awaiting actors was so big that after fulfilling their requests the buffer is almost empty again, we send <code>FetchFromRandomOrg</code> immediately one more time. It can get even more interesting - imagine the buffer is empty and we still haven't satisfied all pending actors. The following code handles all these twists:<br /><br /><pre class="brush: scala">class RandomOrgBuffer extends Actor with ActorLogging {<br /><br />  val BatchSize = 50<br /><br />  val buffer = new Queue[Int]<br />  val backlog = new Queue[ActorRef]<br />  var waitingForResponse = false<br /><br />  //...<br /><br />  def receive = LoggingReceive {<br />    case RandomRequest =&gt;<br />      preFetchIfAlmostEmpty()<br />      if(buffer.isEmpty) {<br />        backlog += sender<br />      } else {<br />        sender ! buffer.dequeue()<br />      }<br />    case RandomOrgServerResponse(randomNumbers) =&gt;<br />      buffer ++= randomNumbers<br />      waitingForResponse = false<br />      while(!backlog.isEmpty &amp;&amp; !buffer.isEmpty) {<br />        backlog.dequeue() ! buffer.dequeue()<br />      }<br />      preFetchIfAlmostEmpty()<br />  }<br /><br />}<br /></pre>In our final version the <code>backlog</code> queue represents pending actors. Notice how <code>RandomOrgServerResponse</code> is handled: if first tries to satisfy as many pending actors as possible. Obviously our goal was to eliminate extremely big response times so we should strive to minimal <code>backlog</code> queue usage as every actor placed there is more likely to wait longer. In ideal world <code>backlog</code> queue is always empty and the <code>RandomOrgBuffer</code> adjusts the batch size requested each time depending on current load (fetching smaller or bigger batches as well as adjusting the threshold below which buffer is considered almost empty). But I'll leave these improvements to you. Finally we can measure <code>RandomOrgBuffer</code> response times (linear scale, latencies are no longer so unevenly distributed):<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-GWkDmLJJOaA/UJQeTpMvCaI/AAAAAAAAApc/8n2H6GpR4ng/s1600/response-times2.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" height="496" src="http://4.bp.blogspot.com/-GWkDmLJJOaA/UJQeTpMvCaI/AAAAAAAAApc/8n2H6GpR4ng/s640/response-times2.png" width="640" /></a></div><br /><br />Handling of incoming messages in <code>RandomOrgBuffer</code> became quite complex. I'm especially worried about the <code>waitingForResponse</code> flag (I hate flags!) In the next article we will learn how to deal with this in very clear, idiomatic and object-oriented way.<br /><br /><blockquote>This was a translation of my article <a href="http://scala.net.pl/poznajemy-akka-dwoch-aktorow/">"<i>Poznajemy Akka: dwóch aktorów</i>"</a> originally published on <a href="http://scala.net.pl/">scala.net.pl</a>.</blockquote><script src="https://raw.github.com/gist/3983275/936845e66d98bb7c627684df7884f33b2cc368f5/syntaxhighlighter.js"></script>