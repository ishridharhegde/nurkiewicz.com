---
layout: post
title: 'Small scale stream processing kata. Part 2: RxJava 1.x/2.x'
date: '2016-10-13T19:39:00.003+02:00'
author: Tomasz Nurkiewicz
tags:
- concurrency
- rxjava
modified_time: '2016-10-13T19:39:44.112+02:00'
blogger_id: tag:blogger.com,1999:blog-6753769565491687768.post-3817705035317284328
blogger_orig_url: https://www.nurkiewicz.com/2016/10/small-scale-stream-processing-kata-part_13.html
---

In <a href="http://www.nurkiewicz.com/2016/10/small-scale-stream-processing-kata-part.html">part 1: thread pools</a> we designed and implemented relatively simple system for processing events in real time. Make sure you read previous part as it contains some classes that we'll reuse. Just in case here are the requirements:<br/><br/> <hr /> A system delivers around one thousand events per second. Each <code>Event</code> has at least two attributes:<br/><br/> <ul><li><code>clientId</code> - we expect up to few events per second for one client</li><li><code>UUID</code> - globally unique</li></ul> Consuming one event takes about 10 milliseconds. Design a consumer of such stream that:<br/><br/> <ol style="list-style-type: decimal"><li>allows processing events in real time</li><li>events related to one client should be processed sequentially and in order, i.e. you can not parallelize events for the same <code>clientId</code></li><li>if duplicated <code>UUID</code> appeared within 10 seconds, drop it. Assume duplicates will not appear after 10 seconds</li></ol><hr /> What we came up so far was a combination of thread pools and shared cache. This time we will implement the solution using RxJava. First of all I never revealed how <code>EventStream</code> is implemented, only giving the API:<br/><br/> <pre class="brush: java">interface EventStream {<br /><br />    void consume(EventConsumer consumer);<br /><br />}</pre> In fact for manual testing I built a simple RxJava stream that behaves like the system from the requirements:<br/><br/> <pre class="brush: java">@Slf4j<br />class EventStream {<br /><br />    void consume(EventConsumer consumer) {<br />        observe()<br />            .subscribe(<br />                consumer::consume,<br />                e -&gt; log.error(&quot;Error emitting event&quot;, e)<br />        );<br />    }<br /><br />    Observable&lt;Event&gt; observe() {<br />        return Observable<br />                .interval(1, TimeUnit.MILLISECONDS)<br />                .delay(x -&gt; Observable.timer(RandomUtils.nextInt(0, 1_000), TimeUnit.MICROSECONDS))<br />                .map(x -&gt; new Event(RandomUtils.nextInt(1_000, 1_100), UUID.randomUUID()))<br />                .flatMap(this::occasionallyDuplicate, 100)<br />                .observeOn(Schedulers.io());<br />    }<br /><br />    private Observable&lt;Event&gt; occasionallyDuplicate(Event x) {<br />        final Observable&lt;Event&gt; event = Observable.just(x);<br />        if (Math.random() &gt;= 0.01) {<br />            return event;<br />        }<br />        final Observable&lt;Event&gt; duplicated =<br />                event.delay(RandomUtils.nextInt(10, 5_000), TimeUnit.MILLISECONDS);<br />        return event.concatWith(duplicated);<br />    }<br /><br />}</pre> Understanding how this simulator works is not essential, but quite interesting. First we generate steady stream of <code>Long</code> values (<code>0</code>, <code>1</code>, <code>2</code>...) every millisecond (thousand events per second) using <code>interval()</code> operator. Then we delay each event by random amount of time between <code>0</code> and <code>1_000</code> microseconds with <code>delay()</code> operator. This way events will appears in less predictable moments in time, a bit more realistic situation. Finally we map (using, ekhem, <code>map()</code> operator) each <code>Long</code> value to a random <code>Event</code> with <code>clientId</code> somewhere between <code>1_000</code> and <code>1_100</code> (inclusive-exclusive).<br/><br/>  The last bit is interesting. We would like to simulate occasional duplicates. In order to do so we map every event (using <code>flatMap()</code>) to itself (in 99% of the cases). However in 1% of the cases we return this event twice, where the second occurrence happens between 10 milliseconds and 5 seconds later. In practice the duplicated instance of the event will appear after hundreds of other events, which makes the stream behave really realistically.<br/><br/>  There are two ways to interact with the <code>EventStream</code> - callback based via <code>consume()</code> and stream based via <code>observe()</code>. We can take advantage of <code>Observable&lt;Event&gt;</code> to quickly build processing pipeline very similar in functionality to <em>part 1</em> but much simpler.<br/><br/> <h1 id="missing-backpressure">Missing backpressure</h1> The first naive approach to take advantage of RxJava falls short very quickly:<br/><br/> <pre class="brush: java">EventStream es = new EventStream();<br />EventConsumer clientProjection = new ClientProjection(<br />        new ProjectionMetrics(<br />                new MetricRegistry()));<br /><br />es.observe()<br />        .subscribe(<br />                clientProjection::consume,<br />                e -&gt; log.error(&quot;Fatal error&quot;, e)<br />        );</pre> (<code>ClientProjection</code>, <code>ProjectionMetrics</code> et. al. come from <a href="http://www.nurkiewicz.com/2016/10/small-scale-stream-processing-kata-part.html">part 1</a>). We get <code>MissingBackpressureException</code> almost instantaneously and that was expected. Remember how our first solution was lagging by handling events with more and more latency? RxJava tries to avoid that, as well as avoiding overflow of queues. <code>MissingBackpressureException</code> is thrown because consumer (<code>ClientProjection</code>) is incapable of handling events in real time. This is <em>fail-fast</em> behavior. The quickest solution is to move consumption to a separate thread pool, just like before, but using RxJava's facilities:<br/><br/> <pre class="brush: java">EventStream es = new EventStream();<br />EventConsumer clientProjection = new FailOnConcurrentModification(<br />        new ClientProjection(<br />                new ProjectionMetrics(<br />                        new MetricRegistry())));<br /><br />es.observe()<br />        .flatMap(e -&gt; clientProjection.consume(e, Schedulers.io()))<br />        .window(1, TimeUnit.SECONDS)<br />        .flatMap(Observable::count)<br />        .subscribe(<br />                c -&gt; log.info(&quot;Processed {} events/s&quot;, c),<br />                e -&gt; log.error(&quot;Fatal error&quot;, e)<br />        );</pre> <code>EventConsumer</code> interface has a helper method that can consume events asynchronously on a supplied <code>Scheduler</code>:<br/><br/> <pre class="brush: java">@FunctionalInterface<br />interface EventConsumer {<br />    Event consume(Event event);<br /><br />    default Observable&lt;Event&gt; consume(Event event, Scheduler scheduler) {<br />        return Observable<br />                .fromCallable(() -&gt; this.consume(event))<br />                .subscribeOn(scheduler);<br />    }<br /><br />}</pre> By consuming events using <code>flatMap()</code> in a separate <code>Scheduler.io()</code> each consumption is invoked asynchronously. This time events are processed near real-time, but there is a bigger problem. I decorated <code>ClientProjection</code> with <code>FailOnConcurrentModification</code> for a reason. Events are consumed independently from each other so it may happen that two events for the same <code>clientId</code> are processed concurrently. Not good. Luckily in RxJava solving this problem is much easier than with plain threads:<br/><br/> <pre class="brush: java">es.observe()<br />        .groupBy(Event::getClientId)<br />        .flatMap(byClient -&gt; byClient<br />                .observeOn(Schedulers.io())<br />                .map(clientProjection::consume))<br />        .window(1, TimeUnit.SECONDS)<br />        .flatMap(Observable::count)<br />        .subscribe(<br />                c -&gt; log.info(&quot;Processed {} events/s&quot;, c),<br />                e -&gt; log.error(&quot;Fatal error&quot;, e)<br />        );</pre> A little bit has changed. First of all we group events by <code>clientId</code>. This splits single <code>Observable</code> stream into <em>stream of streams</em>. Each substream named <code>byClient</code> represents all events related to the same <code>clientId</code>. Now if we map over this substream we can be sure that events related to the same <code>clientId</code> are never processed concurrently. The outer stream is lazy so we must subscribe to it. Rather than subscribing to every event separately we collect events every second and count them. This way we receive a single event of type <code>Integer</code> every second representing the number of events consumed per second.<br/><br/> <h1 id="impure-non-idiomatic-error-prone-unsafe-solution-of-deduplication-using-global-state">Impure, non-idiomatic, error-prone, unsafe solution of deduplication using global state</h1> Now we must drop duplicate <code>UUID</code>s. The simplest, yet very foolish way of discarding duplicates is by taking advantage of global state. We can simply filter out duplicates by looking them up in cache available outside of <code>filter()</code> operator:<br/><br/> <pre class="brush: java">final Cache&lt;UUID, UUID&gt; seenUuids = CacheBuilder.newBuilder()<br />        .expireAfterWrite(10, TimeUnit.SECONDS)<br />        .build();<br /><br />es.observe()<br />        .filter(e -&gt; seenUuids.getIfPresent(e.getUuid()) == null)<br />        .doOnNext(e -&gt; seenUuids.put(e.getUuid(), e.getUuid()))<br />        .subscribe(<br />                clientProjection::consume,<br />                e -&gt; log.error(&quot;Fatal error&quot;, e)<br />        );</pre> If you want to monitor the usage of this mechanism simply add metric:<br/><br/> <pre class="brush: java">Meter duplicates = metricRegistry.meter(&quot;duplicates&quot;);<br /><br />es.observe()<br />        .filter(e -&gt; {<br />            if (seenUuids.getIfPresent(e.getUuid()) != null) {<br />                duplicates.mark();<br />                return false;<br />            } else {<br />                return true;<br />            }<br />        })</pre> Accessing global, especially mutable state from inside of operators is very dangerous and undermines the sole purposes of RxJava - simplifying concurrency. Obviously we use thread-safe <code>Cache</code> from Guava, but in many cases it's easy to miss places where shared global mutable state is accessed from multiple threads. If you find yourself mutating some variable outside of the operator chain, be very careful.<br/><br/> <h1 id="custom-distinct-operator-in-rxjava-1.x">Custom <code>distinct()</code> operator in RxJava 1.x</h1> RxJava 1.x has a <code>distinct()</code> operator that presumably does the job:<br/><br/> <pre class="brush: java">es.observe()<br />        .distinct(Event::getUuid)<br />        .groupBy(Event::getClientId)</pre> Unfortunately <code>distinct()</code> stores all keys (<code>UUID</code>s) internally in ever-growing <code>HashSet</code>. But we only care about duplicates in last 10 seconds! By copy-pasting the implementation of <code>DistinctOperator</code> I created <code>DistinctEvent</code> operator that takes advantage of Guava's cache to only store last 10 seconds worth of UUID's. I intentionally hard-coded <code>Event</code> in this operator rather than making it more generic to keep code easier to understand:<br/><br/> <pre class="brush: java">class DistinctEvent implements Observable.Operator&lt;Event, Event&gt; {<br />    private final Duration duration;<br />    <br />    DistinctEvent(Duration duration) {<br />        this.duration = duration;<br />    }<br /><br />    @Override<br />    public Subscriber&lt;? super Event&gt; call(Subscriber&lt;? super Event&gt; child) {<br />        return new Subscriber&lt;Event&gt;(child) {<br />            final Map&lt;UUID, Boolean&gt; keyMemory = CacheBuilder.newBuilder()<br />                    .expireAfterWrite(duration.toMillis(), TimeUnit.MILLISECONDS)<br />                    .&lt;UUID, Boolean&gt;build().asMap();<br />            <br />            @Override<br />            public void onNext(Event event) {<br />                if (keyMemory.put(event.getUuid(), true) == null) {<br />                    child.onNext(event);<br />                } else {<br />                    request(1);<br />                }<br />            }<br />            <br />            @Override<br />            public void onError(Throwable e) {<br />                child.onError(e);<br />            }<br />            <br />            @Override<br />            public void onCompleted() {<br />                child.onCompleted();<br />            }<br />            <br />        };<br />    }<br />}</pre> The usage is fairly simple and the whole implementation (plus the custom operator) is as short as:<br/><br/> <pre class="brush: java">es.observe()<br />        .lift(new DistinctEvent(Duration.ofSeconds(10)))<br />        .groupBy(Event::getClientId)<br />        .flatMap(byClient -&gt; byClient<br />                .observeOn(Schedulers.io())<br />                .map(clientProjection::consume)<br />        )<br />        .window(1, TimeUnit.SECONDS)<br />        .flatMap(Observable::count)<br />        .subscribe(<br />                c -&gt; log.info(&quot;Processed {} events/s&quot;, c),<br />                e -&gt; log.error(&quot;Fatal error&quot;, e)<br />        );</pre> Actually it can be even shorter if you skip logging every second:<br/><br/> <pre class="brush: java">es.observe()<br />        .lift(new DistinctEvent(Duration.ofSeconds(10)))<br />        .groupBy(Event::getClientId)<br />        .flatMap(byClient -&gt; byClient<br />                .observeOn(Schedulers.io())<br />                .map(clientProjection::consume)<br />        )<br />        .subscribe(<br />                e -&gt; {},<br />                e -&gt; log.error(&quot;Fatal error&quot;, e)<br />        );</pre> This solution is much shorter than previous one based on thread pools and decorators. The only awkward part is custom operator that avoid memory leak when storing too many historic <code>UUID</code>s. Luckily RxJava 2 to the rescue!<br/><br/> <h1 id="rxjava-2.x-and-more-powerful-built-in-distinct">RxJava 2.x and more powerful built-in <code>distinct()</code></h1> I was actually <em>this</em> close from submitting a PR to RxJava with more powerful implementation of <code>distinct()</code> operator. But before I checked <code>2.x</code> branch and there it was: <code>distinct()</code> that allows providing custom <code>Collection</code> as opposed to hard-coded <code>HashSet</code>. Believe it or not, dependency inversion is not only about Spring framework or Java EE. When a library allows you to provide custom implementation of its internal data structure, this is also DI. First I create a helper method that can build <code>Set&lt;UUID&gt;</code> backed by <code>Map&lt;UUID, Boolean&gt;</code> backed by <code>Cache&lt;UUID, Boolean&gt;</code>. We sure like delegation!<br/><br/> <pre class="brush: java">private Set&lt;UUID&gt; recentUuids() {<br />    return Collections.newSetFromMap(<br />            CacheBuilder.newBuilder()<br />                    .expireAfterWrite(10, TimeUnit.SECONDS)<br />                    .&lt;UUID, Boolean&gt;build()<br />                    .asMap()<br />    );<br />}</pre> Having this method we can implement the whole task using this expression:<br/><br/> <pre class="brush: java">es.observe()<br />        .distinct(Event::getUuid, this::recentUuids)<br />        .groupBy(Event::getClientId)<br />        .flatMap(byClient -&gt; byClient<br />                .observeOn(Schedulers.io())<br />                .map(clientProjection::consume)<br />        )<br />        .subscribe(<br />                e -&gt; {},<br />                e -&gt; log.error(&quot;Fatal error&quot;, e)<br />        );</pre> The elegance, the simplicity, the clarity! It reads almost like a problem:<br/><br/> <ul><li>observe a stream of events</li><li>take only distinct UUIDs into account</li><li>group events by client</li><li>for each client consume them (sequentially)</li></ul> Hope you enjoyed all these solutions and you find them useful in your daily work.<br/><br/> <h1>See also:</h1> <ul>    <li><a href="http://www.nurkiewicz.com/2016/10/small-scale-stream-processing-kata-part.html">Small scale stream processing kata. Part 1: thread pools</a></li>    <li>Small scale stream processing kata. Part 2: RxJava 1.x/2.x</li></ul> <script>SyntaxHighlighter.highlight();</script>