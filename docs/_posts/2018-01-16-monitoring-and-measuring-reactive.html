---
layout: post
title: Monitoring and measuring reactive application with Dropwizard Metrics
date: '2018-01-16T00:49:00.001+01:00'
author: Tomasz Nurkiewicz
tags:
- metrics
- dropwizard
- reactor
- grafana
- Graphite
modified_time: '2018-01-25T09:17:06.864+01:00'
thumbnail: https://2.bp.blogspot.com/-GCBValnmEEA/Wl09-PJXWGI/AAAAAAAAVk0/CoAds6OkeIYmBc52VRBTW717dve27gADgCLcBGAs/s72-c/Screen%2BShot%2B2018-01-11%2Bat%2B00.10.52.png
blogger_id: tag:blogger.com,1999:blog-6753769565491687768.post-8573089110894018695
blogger_orig_url: https://www.nurkiewicz.com/2018/01/monitoring-and-measuring-reactive.html
---

In the <a href="http://www.nurkiewicz.com/2018/01/spring-reactor-and-elasticsearch.html">previous article</a> we created a simple indexing code that hammers ElasticSearch with thousands of concurrent requests. The only way to monitor the performance of our system was an old-school logging statement:<br /><br /><pre class="brush: java">.window(Duration.ofSeconds(1))<br />.flatMap(Flux::count)<br />.subscribe(winSize -&gt; log.debug("Got {} responses in last second", winSize));</pre>It's fine, but on a production system, we'd rather have some centralized monitoring and charting solution for gathering various metrics. This becomes especially important once you have hundreds of different applications in thousands of instances. Having a single graphical dashboard, aggregating all important information, becomes crucial. We need two components in order to collect some metrics:<br /><br /><ul><li>publishing metrics</li><li>collecting and visualizing them</li></ul><h1 id="publishing-metrics-using-dropwizard-metrics">Publishing metrics using Dropwizard Metrics</h1>In Spring Boot 2 <a href="http://metrics.dropwizard.io/">Dropwizard Metrics</a> were replaced by <a href="http://micrometer.io/">Micrometer</a>. This article uses the former, the next one will show the latter solution in practice. In order to take advantage of Dropwizard Metrics we must inject <code>MetricRegistry</code> or specific metrics into our business classes.<br /><br /><pre class="brush: java">import com.codahale.metrics.Counter;<br />import com.codahale.metrics.MetricRegistry;<br />import com.codahale.metrics.Timer;<br />import lombok.RequiredArgsConstructor;<br />import lombok.extern.slf4j.Slf4j;<br /><br />@Component<br />@RequiredArgsConstructor<br />class Indexer {<br /><br />    private final PersonGenerator personGenerator;<br />    private final RestHighLevelClient client;<br />    private final Timer indexTimer;<br />    private final Counter indexConcurrent;<br />    private final Counter successes;<br />    private final Counter failures;<br /><br />    public Indexer(PersonGenerator personGenerator, RestHighLevelClient client, MetricRegistry metricRegistry) {<br />        this.personGenerator = personGenerator;<br />        this.client = client;<br />        this.indexTimer = metricRegistry.timer(name("es", "index"));<br />        this.indexConcurrent = metricRegistry.counter(name("es", "concurrent"));<br />        this.successes = metricRegistry.counter(name("es", "successes"));<br />        this.failures = metricRegistry.counter(name("es", "failures"));<br />    }<br /><br />    private Flux&lt;IndexResponse&gt; index(int count, int concurrency) {<br />        //....<br />    }<br /><br />}</pre>So much boilerplate in order to add some metrics!<br /><br /><ul><li><code>indexTimer</code> measures the time distribution (mean, median and various percentiles) of indexing requests</li><li><code>indexConcurrent</code> measures how many requests are currently pending (requests sent, no response received yet); metric goes up and down over time</li><li><code>success</code> and <code>failures</code> counts the total number of successful and failed indexing requests accordingly</li></ul>We will get rid of the boilerplate in a second, but first, let's see how it plays in our business code:<br /><br /><pre class="brush: java">private Mono&lt;IndexResponse&gt; indexDocSwallowErrors(Doc doc) {<br />    return indexDoc(doc)<br />            .doOnSuccess(response -&gt; successes.inc())<br />            .doOnError(e -&gt; log.error("Unable to index {}", doc, e))<br />            .doOnError(e -&gt; failures.inc())<br />            .onErrorResume(e -&gt; Mono.empty());<br />}</pre>This helper method above increments the number of successes and failures every time request completes. Moreover, it logs and swallows errors so that a single error or timeout does not interrupt the whole import process.<br /><br /><pre class="brush: java">private &lt;T&gt; Mono&lt;T&gt; countConcurrent(Mono&lt;T&gt; input) {<br />    return input<br />            .doOnSubscribe(s -&gt; indexConcurrent.inc())<br />            .doOnTerminate(indexConcurrent::dec);<br />}</pre>Another method above increments the <code>indexConcurrent</code> metric when new request is sent and decrements it once result or error arrives. This metrics keeps going up and down, showing the number of in-flight requests.<br /><br /><pre class="brush: java">private &lt;T&gt; Mono&lt;T&gt; measure(Mono&lt;T&gt; input) {<br />    return Mono<br />            .fromCallable(indexTimer::time)<br />            .flatMap(time -&gt;<br />                    input.doOnSuccess(x -&gt; time.stop())<br />            );<br />}</pre>The final helper method is the most complex. It measures the total time of indexing, i.e. the time between the request being sent and the response received. As a matter of fact, it's quite generic, it simply calculates the total time between a subscription to arbitrary <code>Mono&lt;T&gt;</code> and when it completes. Why does it look so weird? Well, the basic <code>Timer</code> API is very simple:<br /><br /><pre class="brush: java">indexTimer.time(() -&gt; someSlowCode())</pre>It simply takes a lambda expression and measures how long did it took to invoke it. Alternatively you can create small <code>Timer.Context</code> object that remembers when it was created. When you call <code>Context.stop()</code> it reports this measurement:<br /><br /><pre class="brush: java">final Timer.Context time = indexTimer.time();<br />someSlowCode();<br />time.stop();</pre>With asynchronous streams it's much harder. Starting of a task (denoted by subscription) and completion typically happens across thread boundaries in different places in code. What we can do is create (lazily) a new <code>Context</code> object (see: <code>fromCallable(indexTimer::time)</code>) and when wrapped stream completes, complete the <code>Context</code> (see: <code>input.doOnSuccess(x -&gt; time.stop()</code>). This is how you compose all these methods:<br /><br /><pre class="brush: java">personGenerator<br />            .infinite()<br />            .take(count)<br />            .flatMap(doc -&gt; <br />                countConcurrent(measure(indexDocSwallowErrors(doc))), concurrency);</pre>That's it, but polluting business code with so many low-level details of metric collecting seems odd. Let's wrap these metrics with a specialized component:<br /><br /><pre class="brush: java">@RequiredArgsConstructor<br />class EsMetrics {<br /><br />    private final Timer indexTimer;<br />    private final Counter indexConcurrent;<br />    private final Counter successes;<br />    private final Counter failures;<br /><br />    void success() {<br />        successes.inc();<br />    }<br /><br />    void failure() {<br />        failures.inc();<br />    }<br /><br />    void concurrentStart() {<br />        indexConcurrent.inc();<br />    }<br /><br />    void concurrentStop() {<br />        indexConcurrent.dec();<br />    }<br /><br />    Timer.Context startTimer() {<br />        return indexTimer.time();<br />    }<br /><br />}</pre>Now we can use a little it bit more high-level abstraction:<br /><br /><pre class="brush: java">class Indexer {<br /><br />    private final EsMetrics esMetrics;<br /><br />    private &lt;T&gt; Mono&lt;T&gt; countConcurrent(Mono&lt;T&gt; input) {<br />        return input<br />                .doOnSubscribe(s -&gt; esMetrics.concurrentStart())<br />                .doOnTerminate(esMetrics::concurrentStop);<br />    }<br /><br />    private &lt;T&gt; Mono&lt;T&gt; measure(Mono&lt;T&gt; input) {<br />        return Mono<br />                .fromCallable(esMetrics::startTimer)<br />                .flatMap(time -&gt;<br />                        input.doOnSuccess(x -&gt; time.stop())<br />                );<br />    }<br /><br /><br />    //...<br /><br />    private Mono&lt;IndexResponse&gt; indexDocSwallowErrors(Doc doc) {<br />        return indexDoc(doc)<br />                .doOnSuccess(response -&gt; esMetrics.success())<br />                .doOnError(e -&gt; log.error("Unable to index {}", doc, e))<br />                .doOnError(e -&gt; esMetrics.failure())<br />                .onErrorResume(e -&gt; Mono.empty());<br />    }<br />}</pre>In the next article we will learn how to compose all these methods even better. And avoid some boilerplate.<br /><br /><h2 id="publishing-and-visualizing-metrics">Publishing and visualizing metrics</h2>Collecting metrics on its own is not enough. We must publish aggregated metrics periodically so that other systems can consume, process and visualize them. One such tool is <a href="https://graphiteapp.org/">Graphite</a> and <a href="https://grafana.com/">Grafana</a>. But before we dive into configuring them, let's first publish metrics to the console. I find this especially useful when troubleshooting metrics or during development.<br /><br /><pre class="brush: java">import com.codahale.metrics.MetricRegistry;<br />import com.codahale.metrics.Slf4jReporter;<br /><br />@Bean<br />Slf4jReporter slf4jReporter(MetricRegistry metricRegistry) {<br />    final Slf4jReporter slf4jReporter = Slf4jReporter.forRegistry(metricRegistry.build();<br />    slf4jReporter.start(1, TimeUnit.SECONDS);<br />    return slf4jReporter;<br />}</pre>This simple code snippet takes an existing <code>MetricRegistry</code> and registers <code>Slf4jReporter</code>. Once every second you'll see all metrics printed to your logs (Logback, etc.):<br /><br /><pre class="brush: java">type=COUNTER, name=es.concurrent, count=1<br />type=COUNTER, name=es.failures, count=0<br />type=COUNTER, name=es.successes, count=1653<br />type=TIMER, name=es.index, count=1653, min=1.104664, max=345.139385, mean=2.2166538118720576,<br />    stddev=11.208345077801448, median=1.455504, p75=1.660252, p95=2.7456, p98=5.625456, p99=9.69689, p999=85.062713,<br />    mean_rate=408.56403102372764, m1=0.0, m5=0.0, m15=0.0, rate_unit=events/second, duration_unit=milliseconds</pre>But that's just or troubleshooting, in order to publish our metrics to an external Graphite instance, we need a <code>GraphiteReporter</code>:<br /><br /><pre class="brush: java">import com.codahale.metrics.MetricRegistry;<br />import com.codahale.metrics.graphite.Graphite;<br />import com.codahale.metrics.graphite.GraphiteReporter;<br /><br />@Bean<br />GraphiteReporter graphiteReporter(MetricRegistry metricRegistry) {<br />    final Graphite graphite = new Graphite(new InetSocketAddress("localhost", 2003));<br />    final GraphiteReporter reporter = GraphiteReporter.forRegistry(metricRegistry)<br />            .prefixedWith("elastic-flux")<br />            .convertRatesTo(TimeUnit.SECONDS)<br />            .convertDurationsTo(TimeUnit.MILLISECONDS)<br />            .build(graphite);<br />    reporter.start(1, TimeUnit.SECONDS);<br />    return reporter;<br />}</pre>Here I'm reporting to <code>localhost:2003</code> where my <a href="https://github.com/kamon-io/docker-grafana-graphite">Docker image with Graphite + Grafana</a> happens to be. Once every second all metrics are sent to this address. We can later visualize all these metrics on Grafana:<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="https://2.bp.blogspot.com/-GCBValnmEEA/Wl09-PJXWGI/AAAAAAAAVk0/CoAds6OkeIYmBc52VRBTW717dve27gADgCLcBGAs/s1600/Screen%2BShot%2B2018-01-11%2Bat%2B00.10.52.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" data-original-height="643" data-original-width="1600" height="128" src="https://2.bp.blogspot.com/-GCBValnmEEA/Wl09-PJXWGI/AAAAAAAAVk0/CoAds6OkeIYmBc52VRBTW717dve27gADgCLcBGAs/s320/Screen%2BShot%2B2018-01-11%2Bat%2B00.10.52.png" width="320" /></a></div><br /><br />The top diagram displays the indexing time distribution (from 50th to 99.9th percentile). Using this diagram you can quickly discover what is the typical performance (P50) as well as (almost) worst case performance (P99.9). The logarithmic scale is unusual but in this case allows us to see both low and high percentiles. The bottom diagram is even more interesting. It combines three metrics:<br /><br /><ul><li>rate (requests per second) of successful index operations</li><li>rate of failed operations (red bar, stacked on top of the green one)</li><li>current concurrency level (right axis): number of in-flight request</li></ul>This diagram shows the system throughput (RPS), failures and concurrency. Too many failures or unusually high concurrency level (many operations pending for response) might be a sign of some issues with your system. The <a href="https://github.com/nurkiewicz/elastic-flux/blob/dropwizard/src/main/docs/grafana-elastic-flux-dropwizard.json">dashboard definition</a> is available in the GitHub repository.<br /><br />In the next article, we will learn how to migrate from Dropwizard Metrics to Micrometer. A very pleasant experience!<br /><br /> <p>This is part of a longer series:</p> <ul> <li><a href="http://www.nurkiewicz.com/2018/01/spring-reactor-and-elasticsearch-from.html">Spring, Reactor and ElasticSearch: from callbacks to reactive streams</a></li> <li><a href="http://www.nurkiewicz.com/2018/01/spring-reactor-and-elasticsearch.html">Spring, Reactor and ElasticSearch: bechmarking with fake test data</a></li> <li>Monitoring and measuring reactive application with Dropwizard Metrics</li> <li><a href="http://www.nurkiewicz.com/2018/01/spring-boot-2-migrating-from-dropwizard.html">Spring Boot 2: Migrating from Dropwizard metrics to Micrometer</a></li> <li><a href="http://www.nurkiewicz.com/2018/01/spring-boot-2-fluxes-from-elasticsearch.html">Spring Boot 2: Fluxes, from Elasticsearch to controller</a></li></ul>   <script>SyntaxHighlighter.highlight();</script>