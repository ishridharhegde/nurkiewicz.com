---
layout: post
title: ExecutorCompletionService in practice
date: '2013-02-22T21:57:00.000+01:00'
author: Tomasz Nurkiewicz
tags:
- multithreading
- concurrency
modified_time: '2013-02-22T21:58:59.656+01:00'
thumbnail: http://1.bp.blogspot.com/-P21mJsD-qoo/USfbJnuJ--I/AAAAAAAAAuY/2wMzPxUtidY/s72-c/169795_121654737900338_452280_o.jpg
blogger_id: tag:blogger.com,1999:blog-6753769565491687768.post-5923311808164322969
blogger_orig_url: https://www.nurkiewicz.com/2013/02/executorcompletionservice-in-practice.html
---

<table cellpadding="0" cellspacing="0" class="tr-caption-container" style="float: left; margin-right: 1em; text-align: left;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/-P21mJsD-qoo/USfbJnuJ--I/AAAAAAAAAuY/2wMzPxUtidY/s1600/169795_121654737900338_452280_o.jpg" imageanchor="1" style="clear: left; margin-bottom: 1em; margin-left: auto; margin-right: auto;"><img border="0" height="240" src="http://1.bp.blogspot.com/-P21mJsD-qoo/USfbJnuJ--I/AAAAAAAAAuY/2wMzPxUtidY/s320/169795_121654737900338_452280_o.jpg" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Holmenkollen district</td></tr></tbody></table>Everyone is talking about the future of Java, we continue our journey explaining <code>Future&lt;T&gt;</code> interface in Java. <a href="http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ExecutorCompletionService.html"><code>ExecutorCompletionService</code></a> wrapper class tries to address one of the biggest deficiencies of <code>Future&lt;T&gt;</code> type - no support for callbacks or any event-driven behaviour whatsoever. Let's go back for a moment to our <a href="http://nurkiewicz.blogspot.no/2013/02/javautilconcurrentfuture-basics.html">sample asynchronous task</a> downloading contents of a given URL:<br /><br /><pre class="brush: java">final ExecutorService pool = Executors.newFixedThreadPool(10);<br />pool.submit(new Callable&lt;String&gt;() {<br />    @Override<br />    public String call() throws Exception {<br />        try (InputStream input = url.openStream()) {<br />            return IOUtils.toString(input, StandardCharsets.UTF_8);<br />        }<br />    }<br />});<br /></pre>Having such code we can easily write a simple web search engine/crawler, examining several URLs concurrently:<br /><br /><pre class="brush: java">final List&lt;String&gt; topSites = Arrays.asList(<br />        "www.google.com", "www.youtube.com", "www.yahoo.com", "www.msn.com",<br />        "www.wikipedia.org", "www.baidu.com", "www.microsoft.com", "www.qq.com",<br />        "www.bing.com", "www.ask.com", "www.adobe.com", "www.taobao.com",<br />        "www.youku.com", "www.soso.com", "www.wordpress.com", "www.sohu.com",<br />        "www.windows.com", "www.163.com", "www.tudou.com", "www.amazon.com"<br />);<br /><br />final ExecutorService pool = Executors.newFixedThreadPool(5);<br />List&lt;Future&lt;String&gt;&gt; contentsFutures = new ArrayList&lt;&gt;(topSites.size());<br />for (final String site : topSites) {<br />    final Future&lt;String&gt; contentFuture = pool.submit(new Callable&lt;String&gt;() {<br />        @Override<br />        public String call() throws Exception {<br />            return IOUtils.toString(new URL("http://" + site), StandardCharsets.UTF_8);<br />        }<br />    });<br />    contentsFutures.add(contentFuture);<br />}<br /></pre>As easy as that. We simply submit separate task for each web site to a pool and wait for results. To achieve that we collect all <code>Future&lt;String&gt;</code> objects into a collection and iterate through them:<br /><a name='more'></a><br /><br /><pre class="brush: java">for (Future&lt;String&gt; contentFuture : contentsFutures) {<br />    final String content = contentFuture.get();<br />    //...process contents<br />}<br /></pre>Each call to <code>contentFuture.get()</code> waits until downloading given web site (remember that each <code>Future</code> represent one site) is finished. This works, but has a major bottleneck. Imagine you have as many threads in a pool as tasks (20 sites in that case). I think it's understandable that you want to start processing contents of web sites as soon as they arrive, no matter which one is first. Response times vary greatly so don't be surprised to find some web sites responding within a second while others need even 20 seconds. But here's the problem: after submitting all the tasks we block on an arbitrary <code>Future&lt;T&gt;</code>. There is no guarantee that this <code>Future</code> will complete first. It is very likely that other <code>Future</code> objects already completed and are ready for processing but we keep hanging on that arbitrary, first <code>Future</code>. In worst case scenario, if the first submitted page is slower by an order of magnitude compared to all the others, all the results except the first one are ready for processing and idle, while we keep waiting for the first one.<br /><br />The obvious solution would be to sort web sites from fastest to slowest and submit them in that order. Then we would be guaranteed that <code>Future</code>s complete in the order in which we submitted them. But this is impractical and almost impossible in real life due to dynamic nature of web.<br /><br />This is where <code>ExecutorCompletionService</code> steps in. It is a thin wrapper around <a href="http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/ExecutorService.html"><code>ExecutorService</code></a> that "remembers" all submitted tasks and allows you to wait for the first <i>completed</i>, as opposed to first <i>submitted</i> task. In a way <code>ExecutorCompletionService</code> keeps a handle to all intermediate <code>Future</code> objects and once any of them finishes, it's returned. Crucial API method is <a href="http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/CompletionService.html#take()"><code>CompletionService.take()</code></a> that blocks and waits for <i>any</i> underlying <code>Future</code> to complete. Here is the submit step with <code>ExecutorCompletionService</code>:<br /><br /><pre class="brush: java">final ExecutorService pool = Executors.newFixedThreadPool(5);<br />final ExecutorCompletionService&lt;String&gt; completionService = new ExecutorCompletionService&lt;&gt;(pool);<br />for (final String site : topSites) {<br />    completionService.submit(new Callable&lt;String&gt;() {<br />        @Override<br />        public String call() throws Exception {<br />            return IOUtils.toString(new URL("http://" + site), StandardCharsets.UTF_8);<br />        }<br />    });<br />}<br /></pre>Notice how we seamlessly switched to <code>completionService</code>. Now the retrieval step:<br /><br /><pre class="brush: java">for(int i = 0; i &lt; topSites.size(); ++i) {<br />    final Future&lt;String&gt; future = completionService.take();<br />    try {<br />        final String content = future.get();<br />        //...process contents<br />    } catch (ExecutionException e) {<br />        log.warn("Error while downloading", e.getCause());<br />    }<br />}<br /></pre>You might be wondering why we need an extra counter? Unfortunately <code>ExecutorCompletionService</code> doesn't tell you how many <code>Future</code> objects are still there waiting so you must remember how many times to call <code>take()</code>.<br /><br />This solution feels much more robust. We process responses immediately when they are ready. <code>take()</code> blocks until fastest task still running finishes. And if processing takes a little bit longer and multiple responses finished, subsequent call to <code>take()</code> will return immediately. It's fun to observe the program when number of pool threads is as big as the number of tasks so that we begin downloading each site at the same time. You can easily see which websites have shortest response time and which respond very slowly.<br /><br /><hr /><code>ExecutorCompletionService</code> seems wonderful, but in fact it is quite limited. You cannot use it with arbitrary collection of <code>Future</code> objects which you happened to obtain somehow. It works only with <code>Executor</code> abstraction. Also there is no built in support for processing incoming results concurrently as well. If we want to parse results concurrently, we need to manually submit them to a second thread pool. In the next few articles I will show you more powerful constructs that mitigate these disadvantages.  <script src="https://raw.github.com/gist/3983275/936845e66d98bb7c627684df7884f33b2cc368f5/syntaxhighlighter.js"></script>