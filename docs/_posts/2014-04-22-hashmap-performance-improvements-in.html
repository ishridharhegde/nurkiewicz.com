---
layout: post
title: HashMap performance improvements in Java 8
date: '2014-04-22T22:54:00.000+02:00'
author: Tomasz Nurkiewicz
tags:
- benchmarks
- caliper
- java 8
- performance
modified_time: '2014-04-22T22:54:01.965+02:00'
thumbnail: http://3.bp.blogspot.com/-2Etpfp9W7_M/U1bWkTWMQ5I/AAAAAAAABBU/_6QAVF55jA4/s72-c/1.png
blogger_id: tag:blogger.com,1999:blog-6753769565491687768.post-3448294383677686637
blogger_orig_url: https://www.nurkiewicz.com/2014/04/hashmap-performance-improvements-in.html
---

<code>HashMap&lt;K, V&gt;</code> is fast, versatile and ubiquitous data structure in every Java program. First some basics. As you probably know, it uses <code>hashCode()</code> and <code>equals()</code> method of keys to split values between buckets. The number of buckets (bins) should be slightly higher than the number of entries in a map, so that each bucket holds only few (preferably one) value. When looking up by key, we very quickly determine bucket (using <code>hashCode()</code> modulo <code>number_of_buckets</code>) and our item is available at constant time.<br /><br />This should have already been known to you. You probably also know that hash collisions have disastrous impact on <code>HashMap</code> performance. When multiple <code>hashCode()</code> values end up in the same bucket, values are placed in an ad-hoc linked list. In worst case, when all keys are mapped to the same bucket, thus degenerating hash map to linked list - from O(1) to O(n) lookup time. Let's first benchmark how <code>HashMap</code> behaves under normal circumstances in Java 7 (1.7.0_40) and Java 8 (1.8.0-b132). To have full control over <code>hashCode()</code> behaviour we define our custom <code>Key</code> class:<br /><br /><pre class="brush: java">class Key implements Comparable&lt;Key&gt; {<br /><br />    private final int value;<br /><br />    Key(int value) {<br />        this.value = value;<br />    }<br /><br />    @Override<br />    public int compareTo(Key o) {<br />        return Integer.compare(this.value, o.value);<br />    }<br /><br />    @Override<br />    public boolean equals(Object o) {<br />        if (this == o) return true;<br />        if (o == null || getClass() != o.getClass())<br />            return false;<br />        Key key = (Key) o;<br />        return value == key.value;<br />    }<br /><br />    @Override<br />    public int hashCode() {<br />        return value;<br />    }<br />}<br /></pre><code>Key</code> class is well-behaving: it overrides <code>equals()</code> and provides decent <code>hashCode()</code>. To avoid excessive GC I cache immutable <code>Key</code> instances rather than creating them from scratch over and over:<br /><br /><pre class="brush: java">public class Keys {<br /><br />    public static final int MAX_KEY = 10_000_000;<br />    private static final Key[] KEYS_CACHE = new Key[MAX_KEY];<br /><br />    static {<br />        for (int i = 0; i &lt; MAX_KEY; ++i) {<br />            KEYS_CACHE[i] = new Key(i);<br />        }<br />    }<br /><br />    public static Key of(int value) {<br />        return KEYS_CACHE[value];<br />    }<br /><br />}<br /></pre>Now we are ready to experiment a little bit. Our benchmark will simply create <code>HashMap</code>s of different sizes (powers of 10, from 1 to 1 million) using continuous key space. In the benchmark itself we will lookup values by key and measure how long it takes, depending on the <code>HashMap</code> size:<br /><br /><pre class="brush: java">import com.google.caliper.Param;<br />import com.google.caliper.Runner;<br />import com.google.caliper.SimpleBenchmark;<br /><br />public class MapBenchmark extends SimpleBenchmark {<br /><br />    private HashMap&lt;Key, Integer&gt; map;<br /><br />    @Param<br />    private int mapSize;<br /><br />    @Override<br />    protected void setUp() throws Exception {<br />        map = new HashMap&lt;&gt;(mapSize);<br />        for (int i = 0; i &lt; mapSize; ++i) {<br />            map.put(Keys.of(i), i);<br />        }<br />    }<br /><br />    public void timeMapGet(int reps) {<br />        for (int i = 0; i &lt; reps; i++) {<br />            map.get(Keys.of(i % mapSize));<br />        }<br />    }<br /><br />}<br /></pre>The results confirm that <code>HashMap.get()</code> is indeed O(1):<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-2Etpfp9W7_M/U1bWkTWMQ5I/AAAAAAAABBU/_6QAVF55jA4/s1600/1.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://3.bp.blogspot.com/-2Etpfp9W7_M/U1bWkTWMQ5I/AAAAAAAABBU/_6QAVF55jA4/s1600/1.png" height="323" width="640" /></a></div>Interestingly Java 8 is on average 20% faster than Java 7 in simple <code>HashMap.get()</code>. The overall performance is equally interesting: even with one million entries in a <code>HashMap</code> a single lookup taken less than 10 nanoseconds, which means around 20 CPU cycles on my machine<sup>*</sup>. Pretty impressive! But that's not what we were about to benchmark. <br /><br />Suppose that we have a very poor map key that always returns the same value. This is the worst case scenario that defeats the purpose of using <code>HashMap</code> altogether:<br /><br /><pre class="brush: java">class Key implements Comparable&lt;Key&gt; {<br /><br />    //...<br /><br />    @Override<br />    public int hashCode() {<br />        return 0;<br />    }<br />}<br /></pre>I used the exact same benchmark to see how it behaves for various map sizes (notice it's a log-log scale):<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/-FWSDLTiO2pw/U1bWkS9YPaI/AAAAAAAABBo/M6MBf0zkovI/s1600/2.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://2.bp.blogspot.com/-FWSDLTiO2pw/U1bWkS9YPaI/AAAAAAAABBo/M6MBf0zkovI/s1600/2.png" height="310" width="640" /></a></div>Results for Java 7 are to be expected. The cost of <code>HashMap.get()</code> grows proportionally to the size of the <code>HashMap</code> itself. Since all entries are in the same bucket in one huge linked list, looking up one requires traversing half of such list (of size n) on average. Thus O(n) complexity as visualized on the graph.<br /><br />But Java 8 performs so much better! It's a log scale so we are actually talking about several orders of magnitude better. The same benchmark executed on JDK 8 yields O(logn) worst case performance in case of catastrophic hash collisions, as pictured better if JDK 8 is visualized alone on a log-linear scale:<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/-IkAmbxqjdmw/U1bWkY4S-CI/AAAAAAAABBg/wS2N7p36eZI/s1600/3.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://2.bp.blogspot.com/-IkAmbxqjdmw/U1bWkY4S-CI/AAAAAAAABBg/wS2N7p36eZI/s1600/3.png" height="382" width="640" /></a></div>What is the reason behind such a tremendous performance improvement, even in terms of big-O notation? Well, this optimization is described in <a href="http://openjdk.java.net/jeps/180">JEP-180</a>. Basically when a bucket becomes too big (currently: <code>TREEIFY_THRESHOLD = 8</code>), <code>HashMap</code> dynamically replaces it with an ad-hoc implementation of tree map. This way rather than having pessimistic O(n) we get much better O(logn). How does it work? Well, previously entries with conflicting keys were simply appended to linked list, which later had to be traversed. Now <code>HashMap</code> promotes list into binary tree, using hash code as a branching variable. If two hashes are different but ended up in the same bucket, one is considered bigger and goes to the right. If hashes are equal (as in our case), <code>HashMap</code> hopes that the keys are <code>Comparable</code>, so that it can establish some order. This is not a requirement of <code>HashMap</code> keys, but apparently a good practice. If keys are not comparable, don't expect any performance improvements in case of heavy hash collisions.<br /><br />Why is all of this so important? Malicious software, aware of hashing algorithm we use, might craft couple of thousand requests that will result in massive hash collisions. Repeatedly accessing such keys will significantly impact server performance, effectively resulting in denial-of-service attack. In JDK 8 an amazing jump from O(n) to O(logn) will prevent such attack vector, also making performance a little bit more predictive. I hope this will finally convince your boss to upgrade. <br /><br /><hr /><sup>*</sup>Benchmarks executed on Intel Core i7-3635QM @ 2.4 GHz, 8 GiB of RAM and SSD drive, running on 64-bit Windows 8.1 and default JVM settings.<br /><br /><script src="https://gist.github.com/nurkiewicz/3983275/raw/936845e66d98bb7c627684df7884f33b2cc368f5/syntaxhighlighter.js"></script>